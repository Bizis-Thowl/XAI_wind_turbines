{
   "cells": [
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error\n",
      "from sklearn.feature_selection import mutual_info_classif\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import scipy"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "train = pd.read_csv(\"./data/first_clean/train_gearbox.csv\", sep=\",\")\n",
      "test = pd.read_csv(\"./data/first_clean/test_gearbox.csv\", sep=\",\")"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "reg_target_name = \"RUL (Target)\"\n",
      "class_target_name = \"Failure (Target)\"\n",
      "drop_cols = [reg_target_name, class_target_name, \"Turbine_ID\", \"Timestamp\", \"Unnamed: 0\", \"index_y\"]\n",
      "train_frac = 0.2\n",
      "fill_method=\"bfill\"\n",
      "\n",
      "filled_train = train.fillna(method=fill_method).sample(frac=train_frac)\n",
      "filled_test = test.fillna(method=fill_method).sample(frac=1)\n",
      "\n",
      "X_train = filled_train.drop(columns=drop_cols)\n",
      "y_train = filled_train[class_target_name]\n",
      "X_test = filled_test.drop(columns=drop_cols)\n",
      "y_test = filled_test[class_target_name]"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "def get_redundant_pairs(X_train):\n",
      "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
      "    pairs_to_drop = set()\n",
      "    cols = X_train.columns\n",
      "    for i in range(0, X_train.shape[1]):\n",
      "        for j in range(0, i+1):\n",
      "            pairs_to_drop.add((cols[i], cols[j]))\n",
      "    return pairs_to_drop\n",
      "\n",
      "def get_top_abs_correlations(X_train, thresholds=[0.5]):\n",
      "    au_corr = X_train.corr().abs().unstack()\n",
      "    labels_to_drop = get_redundant_pairs(X_train)\n",
      "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
      "    au_corrs = []\n",
      "    for threshold in thresholds:\n",
      "        au_corrs.append(au_corr[au_corr > threshold])\n",
      "    return au_corrs\n",
      "\n",
      "def get_indexes_to_drop(corr_df, X_train, y_train):\n",
      "\n",
      "    indexes_to_drop = set()\n",
      "\n",
      "    for row in corr_df.index:\n",
      "        if (X_train[row[0]].corr(y_train)) > (X_train[row[1]].corr(y_train)):\n",
      "            indexes_to_drop.add(row[1])\n",
      "        else:\n",
      "            indexes_to_drop.add(row[0])\n",
      "    \n",
      "    return indexes_to_drop\n",
      "\n",
      "def corr_filter(X_train, y_train, thresholds=[0.5]):\n",
      "    remaining_dfs = []\n",
      "    corr_dfs = get_top_abs_correlations(X_train, thresholds)\n",
      "    for corr_df in corr_dfs:\n",
      "        indexes_to_drop = get_indexes_to_drop(corr_df, X_train, y_train)\n",
      "        remaining_df = X_train.drop(labels=indexes_to_drop, axis=1)\n",
      "        remaining_dfs.append(remaining_df)\n",
      "    return remaining_dfs"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "def mutual_info(X_train, y_train, num_cols=[4]):\n",
      "    output=[]\n",
      "    mutual_info = mutual_info_classif(X_train, y_train)\n",
      "    order = np.argsort(mutual_info)\n",
      "    sorted_cols = np.array(X_train.columns)[order[::-1]]\n",
      "    for col in num_cols:\n",
      "        cutted_cols = sorted_cols[0:col]\n",
      "        output.append(X_train[cutted_cols])\n",
      "    return output"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "y_train.to_list().count(1)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "X_test_compounded = {}\n",
      "\n",
      "corr_filter_thresholds = [0.6]# [0.5, 0.6, 0.7, 0.8, 0.9]\n",
      "mutual_info_cols = [10]# [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
      "\n",
      "X_compounded = {\n",
      "    \"baseline\": [X_train],\n",
      "    \"corr_filter\": [],\n",
      "    \"mutual_info\": [],\n",
      "}\n",
      "\n",
      "X_test_compounded = {\n",
      "    \"baseline\": [X_test],\n",
      "    \"corr_filter\": [],\n",
      "    \"mutual_info\": [],\n",
      "}\n",
      "\n",
      "# Create correlation filter datasets\n",
      "X_compounded[\"corr_filter\"] = corr_filter(X_train, y_train, thresholds=corr_filter_thresholds)\n",
      "\n",
      "for data in X_compounded[\"corr_filter\"]:\n",
      "    X_test_compounded[\"corr_filter\"].append(X_test[data.columns])\n",
      "\n",
      "# Create mutual information datasets\n",
      "X_compounded[\"mutual_info\"] = mutual_info(X_train, y_train, num_cols=mutual_info_cols)\n",
      "\n",
      "for data in X_compounded[\"mutual_info\"]:\n",
      "    X_test_compounded[\"mutual_info\"].append(X_test[data.columns])"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "def train_run(X, y, X_test, y_test, clf):\n",
      "\n",
      "    clf.fit(X, y)\n",
      "    y_test_pred = clf.predict(X_test)\n",
      "    y_train_pred = clf.predict(X)\n",
      "    f1_train = f1_score(y, y_train_pred)\n",
      "    precision = precision_score(y_test, y_test_pred)\n",
      "    recall = recall_score(y_test, y_test_pred)\n",
      "    f1 = f1_score(y_test, y_test_pred)\n",
      "\n",
      "    scores = {\n",
      "        \"f1_train\": f1_train,\n",
      "        \"f1\": f1,\n",
      "        \"precision\": precision,\n",
      "        \"recall\": recall\n",
      "    }\n",
      "\n",
      "    return scores"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "# Utility function to report best scores\n",
      "def report(results, n_top=3):\n",
      "    for i in range(1, n_top + 1):\n",
      "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
      "        for candidate in candidates:\n",
      "            print(\"Model with rank: {0}\".format(i))\n",
      "            print(\n",
      "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
      "                    results[\"mean_test_score\"][candidate],\n",
      "                    results[\"std_test_score\"][candidate],\n",
      "                )\n",
      "            )\n",
      "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
      "            print(\"\")"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "def train_runs(X_compounded, X_test_compounded):\n",
      "    \n",
      "    best_scores = []\n",
      "\n",
      "    for fe_type in X_compounded.keys():\n",
      "        for i in range(len(X_compounded[fe_type])):\n",
      "            X_train_loc = X_compounded[fe_type][i]\n",
      "            X_test_loc = X_test_compounded[fe_type][i]\n",
      "\n",
      "            # base_estimator = DecisionTreeClassifier(random_state=0)\n",
      "            # param_grid = {\n",
      "            #     \"max_depth\": [5, 10, 20],\n",
      "            #     \"min_samples_leaf\": [1, 10]\n",
      "            # }\n",
      "            base_estimator = LogisticRegression(max_iter=300, penalty=\"l2\", class_weight=\"balanced\")\n",
      "            param_grid = {\n",
      "                # \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
      "                # \"class_weight\": [\"balanced\", None],\n",
      "                \"solver\": [\"saga\"]\n",
      "            }\n",
      "            sh = GridSearchCV(base_estimator, param_grid, scoring=\"f1\").fit(X_train_loc, y_train)\n",
      "            clf = sh.best_estimator_\n",
      "            report(sh.cv_results_)\n",
      "\n",
      "            scores = train_run(X_train_loc, y_train, X_test_loc, y_test, clf=clf)\n",
      "            config = {\n",
      "                \"h_param\": corr_filter_thresholds[i],\n",
      "                \"iter\": i\n",
      "            } if fe_type == \"corr_filter\" else None\n",
      "            config = {\n",
      "                \"h_param\": mutual_info_cols[i],\n",
      "                \"iter\": i\n",
      "            } if fe_type == \"mutual_info\" else config\n",
      "\n",
      "            best_scores.append({\n",
      "                \"type\": fe_type, \"config\": config, \"f1_train\": scores[\"f1_train\"], \"f1\": scores[\"f1\"], \n",
      "                \"precision\": scores[\"precision\"], \"recall\": scores[\"recall\"], \"clf\": clf})\n",
      "    \n",
      "    return best_scores"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "best_scores = train_runs(X_compounded, X_test_compounded)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "for score in best_scores:\n",
      "    print(\"Typ: {} mit Einstellung {}:\".format(score[\"type\"], score[\"config\"][\"h_param\"] if score[\"config\"] else None))\n",
      "    print(score[\"clf\"])\n",
      "    print(\"f1 train: {}, f1: {}, precision: {}, recall: {}\".format(score[\"f1_train\"], score[\"f1\"], score[\"precision\"], score[\"recall\"]))"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "best_f1 = 0\n",
      "best_data = None\n",
      "my_clf = None\n",
      "for score in best_scores:\n",
      "    if score[\"f1\"] > best_f1: \n",
      "        best_f1 = score[\"f1\"]\n",
      "        iter = 0\n",
      "        my_clf = score[\"clf\"]\n",
      "        if score[\"config\"] != None:\n",
      "            iter = score[\"config\"][\"iter\"]\n",
      "        best_data = X_compounded[score[\"type\"]][iter]"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "my_data = pd.concat([best_data, y_train], axis=1)\n",
      "my_sample = my_data\n",
      "prediction = my_clf.predict(my_sample.drop(class_target_name, axis=1))\n",
      "actual = my_sample[class_target_name]"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "plt.xticks(rotation=90)\n",
      "plt.bar(best_data.columns, my_clf.feature_importances_)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "actual.to_list().count(1)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "plt.hist(prediction, bins=20)\n",
      "# plt.hist(actual, bins=20)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "drop_cols.remove(\"Unnamed: 0\")\n",
      "train_out = filled_train[drop_cols + best_data.columns.to_list()]\n",
      "test_out = filled_test[drop_cols + best_data.columns.to_list()]"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "test_out.head()"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "check_df = test_out.sort_values(by=\"Timestamp\")"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "plt.plot(check_df[check_df[\"Turbine_ID\"] == \"T06\"][class_target_name])"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "import os\n",
      "os.makedirs(\"./data/feature_selected\", exist_ok=True)"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": [
      "train_out.to_csv(\"./data/feature_selected/train_gearbox_classif.csv\")\n",
      "test_out.to_csv(\"./data/feature_selected/test_gearbox_classif.csv\")"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "source": []
    }
   ],
   "metadata": {
    "kernelspec": {
     "display_name": "Python 3.9.12 ('XAI_wind')",
     "language": "python",
     "name": "python3"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "ipython",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
     "interpreter": {
      "hash": "520723b62f68f94512b4b527a2129921bc4d6da9c94363ee0894f78e84b35631"
     }
    }
   },
   "nbformat": 4,
   "nbformat_minor": 2
  }
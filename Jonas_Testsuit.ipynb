{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4297, 0.1399, 0.5895],\n",
      "        [0.1267, 0.5555, 0.7992],\n",
      "        [0.0270, 0.7630, 0.9163],\n",
      "        [0.9268, 0.5900, 0.2715],\n",
      "        [0.0225, 0.1828, 0.0282]])\n",
      "Cuda is available\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m      7\u001b[0m    \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCuda is available\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m    device_id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mcurrent_device()\n\u001b[0;32m      9\u001b[0m    gpu_properties \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mget_device_properties(device_id)\n\u001b[0;32m     10\u001b[0m    \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFound \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m GPUs available. Using GPU \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) of compute capability \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39mGb total memory.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \n\u001b[0;32m     12\u001b[0m           (torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m           gpu_properties\u001b[39m.\u001b[39mminor,\n\u001b[0;32m     17\u001b[0m           gpu_properties\u001b[39m.\u001b[39mtotal_memory \u001b[39m/\u001b[39m \u001b[39m1e9\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:482\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcurrent_device\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    481\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 482\u001b[0m     _lazy_init()\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32mc:\\Users\\Jonas\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:211\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "   print (\"Cuda is available\")\n",
    "   device_id = torch.cuda.current_device()\n",
    "   gpu_properties = torch.cuda.get_device_properties(device_id)\n",
    "   print(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n",
    "          \"%.1fGb total memory.\\n\" % \n",
    "          (torch.cuda.device_count(),\n",
    "          device_id,\n",
    "          gpu_properties.name,\n",
    "          gpu_properties.major,\n",
    "          gpu_properties.minor,\n",
    "          gpu_properties.total_memory / 1e9))\n",
    "else:    \n",
    "   print (\"Cuda is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "train = pd.read_csv(\"./data/first_clean/train_gearbox.csv\", sep=\",\")\n",
    "test = pd.read_csv(\"./data/first_clean/test_gearbox.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preperation\n",
    "reg_target_name = \"RUL (Target)\"\n",
    "class_target_name = \"Failure (Target)\"\n",
    "drop_cols = [reg_target_name, class_target_name, \"Turbine_ID\", \"Timestamp\", \"Unnamed: 0\", \"index_y\"]\n",
    "\n",
    "x_train_base = train.drop(columns=drop_cols)\n",
    "y_train_base = train[reg_target_name]\n",
    "x_test_base = test.drop(columns=drop_cols)\n",
    "y_test_base = test[reg_target_name]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Construct\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tree \u001b[39m=\u001b[39m DecisionTreeRegressor()\n\u001b[0;32m      3\u001b[0m tree\u001b[39m.\u001b[39mfit(x_train_base, y_train_base)\n\u001b[0;32m      4\u001b[0m y_pred_unprepared \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mpredict(x_test_base)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# Construct\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(x_train_base, y_train_base)\n",
    "y_pred_unprepared = tree.predict(x_test_base)\n",
    "\n",
    "# Evaluation\n",
    "mae_unprepared = mean_absolute_error(y_test_base, y_pred_unprepared)\n",
    "r2_unprepared = r2_score(y_test_base, y_pred_unprepared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amb_WindDir_Relative_Avg  Amb_WindDir_Relative_Avg     1.000000\n",
       "                          Amb_WindDir_Abs_Avg          0.005898\n",
       "                          Prod_LatestAvg_ActPwrGen0    0.003769\n",
       "                          Grd_Prod_Freq_Avg            0.001913\n",
       "                          Grd_Prod_VoltPhse1_Avg       0.010354\n",
       "                                                         ...   \n",
       "Max_Raindetection         Grd_Prod_PsbleCap_Std        0.004288\n",
       "                          Min_Pressure                 0.002255\n",
       "                          Max_Humidity                 0.008384\n",
       "                          Max_Precipitation            0.012336\n",
       "                          Max_Raindetection            1.000000\n",
       "Length: 169, dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if(abs(corr_matrix.iloc[i,j])>threshold):\n",
    "                print(\"t\")\n",
    "\n",
    "# Construct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a561ff09736c45ea8c4c6a2f2879bc77e5e64e20329dfa0346a65d0599b7f690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
